{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-joEc0MczjcJ",
        "outputId": "7b300f72-b2f7-4459-cef0-50d455249bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Model FPS: 24.212140048993096\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import time\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-printed\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-printed\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "def process_video(video_path, model, output_path, device):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    frame_count = 0\n",
        "    total_time = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        inputs = processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "        outputs = model.generate(inputs)\n",
        "        text = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "        end_time = time.time()\n",
        "        total_time += (end_time - start_time)\n",
        "        frame_count += 1\n",
        "\n",
        "        cv2.putText(frame, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    fps = frame_count / total_time\n",
        "    return fps\n",
        "\n",
        "input_video_path = '/content/videoplayback.mp4'\n",
        "gpu_output_video_path = 'gpu_output_video.mp4'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_fps = process_video(input_video_path, model, gpu_output_video_path, device)\n",
        "    print(f\"GPU Model FPS: {gpu_fps}\")\n"
      ]
    }
  ]
}